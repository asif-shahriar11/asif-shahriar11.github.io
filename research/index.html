<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Research | Asif Shahriar </title> <meta name="author" content="Asif Shahriar"> <meta name="description" content="A list of some of my research works."> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://asif-shahriar11.github.io/research/"> <script src="/assets/js/theme.js?a81d82887dd692e91686b43de4542f18"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> Asif Shahriar </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">Publications </a> </li> <li class="nav-item active"> <a class="nav-link" href="/research/">Research <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">projects </a> </li> <li class="nav-item "> <a class="nav-link" href="/education/">Education </a> </li> <li class="nav-item "> <a class="nav-link" href="/work/">Work </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">CV </a> </li> <li class="nav-item dropdown "> <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">submenus </a> <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown"> <a class="dropdown-item " href="/books/">bookshelf</a> <div class="dropdown-divider"></div> <a class="dropdown-item " href="/blog/">blog</a> </div> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">Research</h1> <p class="post-description">A list of some of my research works.</p> </header> <article> <p>My current research interests span across <code class="language-plaintext highlighter-rouge">Computer security</code>, <code class="language-plaintext highlighter-rouge">Adversarial ML</code>, <code class="language-plaintext highlighter-rouge">Natural language processing</code>, and <code class="language-plaintext highlighter-rouge">Trustworthy AI</code>.</p> <p><input id="research-search" class="form-control list-search" type="search" placeholder="Type to filter: topic, title, venue, year, supervisor…"></p> <p style="margin-top:3em;"></p> <h2 id="completed-works">Completed Works</h2> <hr> <h3 id="5gpt-5g-vulnerability-detection-by-combining-zero-shot-capabilities-of-gpt-4-with-domain-aware-strategies-through-prompt-engineering">5GPT: 5G Vulnerability Detection by Combining Zero-Shot Capabilities of GPT-4 With Domain-Aware Strategies Through Prompt Engineering</h3> <p><em>IEEE Transactions on Information Forensics and Security, 2025.</em></p> <p><img src="/assets/img/zero-shot-image.png" alt="Zero-shot approach" class="img-fluid rounded shadow-sm" width="800"> <em>Fig: Zero-shot approach</em></p> <p><img src="/assets/img/domain-aware-image.png" alt="Domain-aware approach" class="img-fluid rounded shadow-sm" width="900"> <em>Fig: Domain-aware approach</em></p> <p>Can LLMs like GPT-4 analyze complex cellular protocol specifications to identify security vulnerabilities? We discovered that out-of-the-box GPT-4 has impressive capabilities in flagging ogical inconsistencies and procedural flaws, but it also hallucinates, provides false positives, and struggles to detect deep protocol issues. To remedy this, we teach GPT-4 to think like a telecom-security expert– what properties must hold, how they fail, and how hazards indicators are exploited by adversaries. The result? A scalable, powerful, efficient black-box framework that can uncover subtle, protocol-level attack vectors that would otherwise slip through the cracks.</p> <p><strong>Supervisor(s):</strong> <a href="https://cse.buet.ac.bd/faculty/faculty_detail/mshohrabhossain" rel="external nofollow noopener" target="_blank">Dr. Md Shohrab Hossain (BUET)</a>, <a href="https://speed.cs.nycu.edu.tw/~ydlin/" rel="external nofollow noopener" target="_blank">Dr. Ying-Dar Lin</a>, <a href="https://rhhwang.csie.io/English/index.html" rel="external nofollow noopener" target="_blank">Dr. Ren-Hung Hwang</a></p> <div class="d-flex flex-wrap gap-2 my-2" role="group" aria-label="5gpt links"> <a class="btn btn-outline-secondary readmore-btn" data-target="#more-5gpt" href="javascript:void(0)">Read more</a> <a class="btn btn-outline-secondary" href="/assets/pdf/5GPT_final.pdf" target="_blank" rel="noopener">PDF</a> <a class="btn btn-outline-secondary" href="/assets/pdf/5GPT_presentation.pdf" target="_blank" rel="noopener">Slides</a> </div> <div id="more-5gpt" class="mt-2 d-none"> <p>LLMs like GPT-4 have been used extensively in code-level security testing. Natural language is difficult; it is unstructured and inherently ambiguous. To assess GPT-4’s capabilities in this domain, we first adopt a zero-shot approach that relies solely on the specification text without any external guidance. On surface level, the results are impressive: GPT-4 is highly effective in detecting high-level logical inconsistencies, weak validation checks, misconfigurations, and ambiguous protocol rules. Examples include improper handling of de-registration request with switch-off indication, inaccurate updating of 5G-GUTI, ambiguous guidelines for SNPN-specific attempt counters, and so on. Althogether GPT-4 identified 25 potential vulnerabilities, of which 12 are new. We tested eight of them and found four true-positives, the remaining four were false-positives. So, on its own GPT-4 is prone to hallucination. Further, GPT-4 is unable to identify advanced, low-level security flaws such as cryptographic weaknesses, exploitable timing and race condition attacks, network layer exploits (including downgrade attacks), and particularly attacks that involve multiple states or entities.</p> <p>To uncover deeper, protocol-level attack vectors with greater precision, GPT-4 needs cdomain-specific contextual understanding. For this we introduce a novel domain-aware strategy, where we explicitly teach GPT-4 about security properties and hazard indicators from related works using few-shot learning. We further employ chain-of-thought prompting to guide the model through structured reasoning steps to identify violations or exploitations that may lead to vulnerabilities. Using the domain-aware approach, we have identified 24 potential vulnerabilities, including 15 new. These include sophisticated vulnerabilities like multi-state and cross-procedure attacks, cryptographic and integrity violations, message spoofing, injection, privacy and identity exposure, and resource management exploits. We tested SIX of these vulnerabilities and confirmed FIVE.</p> <p>We also compared our findings against a white-box model, Mobile-LLaMA, and found that GPT-4 is more capable of finding both logical flaws and real-world exploits.</p> </div> <hr> <h3 id="inceptive-transformers-enhancing-contextual-representations-through-multi-scale-feature-learning-across-domains-and-languages">Inceptive Transformers: Enhancing Contextual Representations through Multi-Scale Feature Learning Across Domains and Languages</h3> <p><em>Accepted for presentation in EMNLP 2025.</em></p> <p><img src="/assets/img/inceptive_transformer_flowchart.png" alt="Inceptive transformers workflow" class="img-fluid rounded shadow-sm" width="900"> <em>Fig: End-to-end workflow of Inceptive Transformer models</em></p> <table> <thead> <tr> <th style="text-align: center"><img src="/assets/img/inceptive_intro.png" alt="Attention maps" width="400"></th> <th style="text-align: center"><img src="/assets/img/best-comp-irony.png" alt="Irony comparison" width="300"></th> <th style="text-align: center"><img src="/assets/img/best-comp-ohsumed.png" alt="OHSUMED comparison" width="300"></th> </tr> </thead> <tbody> <tr> <td style="text-align: center">Attention visualization</td> <td style="text-align: center">Performance comparison (irony)</td> <td style="text-align: center">Performance comparison (OHSUMED)</td> </tr> </tbody> </table> <p>A modular, lightweight, plug-and-play architecture for enhancing the contextual representations of <em><strong>any</strong></em> encoder model. Improves <strong>EIGHT</strong> PLM baselines across <strong>FIVE</strong> tasks for both short/long texts in English and Bangla.</p> <p><strong>Supervisor(s):</strong> <a href="https://cse.buet.ac.bd/faculty/faculty_detail/mrahman" rel="external nofollow noopener" target="_blank">Dr. M Saifur Rahman (BUET)</a>, <a href="https://cse.buet.ac.bd/faculty/faculty_detail/rifat" rel="external nofollow noopener" target="_blank">Dr. Rifat Shahriyar</a></p> <div class="d-flex flex-wrap gap-2 my-2" role="group" aria-label="Inceptive links"> <a class="btn btn-outline-secondary readmore-btn" data-target="#more-inceptive" href="javascript:void(0)">Read more</a> <a class="btn btn-outline-secondary" href="/assets/pdf/5GPT_final.pdf" target="_blank" rel="noopener">PDF</a> <a class="btn btn-outline-secondary" href="https://github.com/asif-shahriar11/inceptive-transformer" target="_blank" rel="noopener">Code</a> </div> <div id="more-inceptive" class="mt-2 d-none"> <p>Encoder models are designed to aggregate all token embeddings into a single representation, called the [CLS] token, which is later used for downstream tasks like classification. Although it is convenient, the over-reliance on a single representative token can make encoder models insufficient in capturing fine-grained contextual nuances or localized cues critical for tasks like emotion recognition or irony detection [left figure]. This issue is even more pronounced in multi-label tasks, which require token-level attention rather than a single sequence-level summary.</p> <p>In this work we propose <em><strong>Inceptive Transformers</strong></em> – a lightweight and modular architecture that augments a transformer baseline by stacking an inception-style 1-D convolution module on top. Instead of using [CLS]-based pooling, we feed the final hidden states from the baseline transformer (e.g. RoBERTa or BioBERT) to a multi-scale feature extraction module. This inception module employs parallel 1-D convolutional filters with varying kernel sizes that are designed to recognize local features, such as key phrases or word combinations that are indicative of specific classifications. The goal of the inception module is to incorporate local features without sacrificing global context, which is achieved by using a residual connection to concatenate the original transformer’s hidden states with the multi-scale features. These enriched features are then processed by a self-attention mechanism, which dynamically assigns weights to tokens based on their task-specific contribution, thus allowing the model to effectively prioritize relevant tokens.</p> <p>Our experiments demonstrate that Inceptive Transformers consistently outperform both general-purpose baselines (like RoBERTa and DeBERTa v3) and domain-specific ones (like BERTweet and BioBERT). On five different tasks (Bangla and English emotion recognition, irony detection, disease identification, and anti-vaccine concern classification), we observed performance gains from <strong>1%</strong> to as high as <strong>14%</strong> in accuracy and F1-score, with less than 10% inference-time overhead. </p> </div> <p style="margin-top:3em;"></p> <h2 id="ongoing-works">Ongoing Works</h2> <hr> <h3 id="5g-vulnerability-testing-using-retrieval-augmented-generation">5G Vulnerability Testing using Retrieval-Augmented Generation</h3> <p><em>Ongoing work.</em></p> <p><img src="/assets/img/rhino.png" alt="5G RAG" class="img-fluid rounded shadow-sm" width="220"></p> <p>In 5GPT, we showed that LLMs are capable of identifying vulnerailities from complex natural language documents like 5G specifications. However, we also showed that LLMs have a tendency to ‘hallucinate’, where they suggest some false-positives. Furthermore, it is difficult for LLMs to capture cross-section vulnerabilities. To address these issues, we propose a novel, fully automated end-to-end framework that utilizes a Retrieval-Augmented Generation (RAG) pipeline to ground LLM outputs in verified, domain-specific data to minimize hallucinations. We also introduce a robust context retrieval mechanism to overcome the cross-section dependency challenges. Using this framework, we have so far generated <strong>800</strong> test-cases for essential 5G mobility management procedures in <strong>under 3 hours</strong>.</p> <p><strong>Supervisor(s):</strong> <a href="https://cse.buet.ac.bd/faculty/faculty_detail/mshohrabhossain" rel="external nofollow noopener" target="_blank">Dr. Md Shohrab Hossain (BUET)</a>, <a href="https://syed-rafiul-hussain.github.io/" rel="external nofollow noopener" target="_blank">Dr. Syed Rafiul Hussain (Penn State)</a></p> <hr> <h3 id="cross-modal-deception-there-is-more-than-what-meets-the-eyes">Cross-modal Deception: There is More than what Meets the Eyes</h3> <p><em>Ongoing work.</em><br> LLMs and VLMs are vulnerable to jailbreak attacks, we know that. In these attacks, the user attempts a number of techniques to elicit harmful responses that the model would generally not produce. In this work we aim to introduce a novel class of attacks that deceive both the user and the VLM. The model is compromised by a hidden instruction, while the human user, who may be interacting with the model through a completely benign-looking image, is an unwitting participant in the attack. If successful, the implications of this attack could be huge.</p> <p><strong>Supervisor(s):</strong> <a href="https://elmi.hbku.edu.qa/en/persons/md-rizwan-parvez" rel="external nofollow noopener" target="_blank">Dr. Rizwan Parvez (QCRI)</a></p> <hr> <h3 id="secured-multi-agent-systems">Secured Multi-agent Systems</h3> <p><em>Ongoing work.</em><br> After the revolution of LLMs, we now see the rise of agentic frameworks that can browse the web, perform grocery shopping from amazon, run OS commands, and what not. <em><strong>But what about security?</strong></em> What if the <em>cheapest deal</em> is being offered at a <em>phishing website?</em> That’s what we aim to found out.</p> <p><strong>Supervisor(s):</strong> <a href="https://elmi.hbku.edu.qa/en/persons/md-rizwan-parvez" rel="external nofollow noopener" target="_blank">Dr. Rizwan Parvez (QCRI)</a></p> <script>
(function () {
  const box = document.getElementById('research-search');
  if (!box) return;
  const items = Array.from(document.querySelectorAll('h3, h4, h5, p, li, strong, em'));
  function hay() {
    return (items.map(n => n.textContent).join(' ') || '').toLowerCase();
  }
  let cache = hay();
  function filter() {
    const q = box.value.trim().toLowerCase();
    if (!q) { document.body.classList.remove('filtering'); [...document.querySelectorAll('section, article, div')]; }
    const blocks = Array.from(document.querySelectorAll('h3, h4, h5')).map(h => h.closest('section, article, div'));
    blocks.forEach(b => {
      const txt = (b.textContent || '').toLowerCase();
      b.style.display = (!q || txt.includes(q)) ? '' : 'none';
    });
  }
  box.addEventListener('input', filter);
})();
</script> <script>
  // Read more / Show less toggler without Bootstrap JS
  (function () {
    document.querySelectorAll('.readmore-btn').forEach(function (btn) {
      const sel = btn.getAttribute('data-target');
      const box = document.querySelector(sel);
      if (!box) return;

      function isHidden(el) { return el.classList.contains('d-none'); }
      function show(el) { el.classList.remove('d-none'); }
      function hide(el) { el.classList.add('d-none'); }

      btn.addEventListener('click', function () {
        if (isHidden(box)) {
          show(box);
          btn.textContent = 'Show less';
        } else {
          hide(box);
          btn.textContent = 'Read more';
        }
      });
    });
  })();
</script> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 Asif Shahriar. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js?a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?c8a01c11a92744d44b093fc3bda915df" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/assets/js/mathjax-setup.js?a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/assets/js/search-setup.js?6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/assets/js/search-data.js"></script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>